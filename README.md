# Multiâ€‘Agent Anomaly Detection

**DÃ©tection dâ€™anomalies rÃ©seau avec LSTM & explications LLM Mistral via FastAPI**

---

## ğŸ¯ Contexte et Objectif

Ce projet combine :
1. Un **modÃ¨le LSTM** entraÃ®nÃ© sur le dataset **UNSWâ€‘NB15** pour dÃ©tecter les fenÃªtres de flux rÃ©seau anormales.
2. Un **LLM local** (Mistralâ€‘7Bâ€‘instruct Q4_K_M) pour gÃ©nÃ©rer des explications techniques et actionnables.
3. Une **API FastAPI** exposant deux endpoints :
   - `/predict` : renvoie la probabilitÃ© et la classe (normal/anomalie).  
   - `/analyze` : retourne la prÃ©diction + des statistiques agrÃ©gÃ©es + une explication dÃ©taillÃ©e du LLM.

---


## âš™ï¸ Installation

1. **Cloner** le dÃ©pÃ´t  
   ```bash
   git clone https://github.com/xxUSERNAMExx/multi-agent-anomaly-detection.git
   cd multi-agent-anomaly-detection

2. CrÃ©er et activer un environnement Python
python -m venv venv
source venv/bin/activate   # macOS/Linux
venv\Scripts\activate      # Windows

3. Installer les dÃ©pendances
pip install fastapi uvicorn llama-cpp-python numpy pandas scikit-learn tensorflow

4. Placer le modÃ¨le Mistral .gguf dans models/, et copier :
- lstm_model.weights.h5
- scaler.pkl
- feature_info.json


## ğŸš€ Lancement
uvicorn main:app --reload

â†’ Lâ€™API tourne sur http://127.0.0.1:8000

Docs interactives : http://127.0.0.1:8000/docs

## ğŸ” Usage
1) PrÃ©diction brute (LSTM)
- POST /predict
   ```bash
   {
  "sequence": [ /* 10 objets flux rÃ©seau */ ]
   }
- RÃ©ponse
   ```bash
  { "probability": 0.0037, "class": 0 }

2) Analyse + explication LLM
- POST /analyze
   ```bash
   {
  "sequence": [ /* 10 objets flux rÃ©seau */ ]
   }
- RÃ©ponse
   ```bash
   {
  "prediction": { "probability":0.0037, "class":0 },
  "statistics": { "count":10, "dur_mean":â€¦ , â€¦ },
  "llm_explanation": "Analyse dÃ©taillÃ©e par Mistralâ€¦"
   }

## ğŸ› ï¸ DÃ©tails techniques
- agent.py

   - Charge scaler.pkl, feature_info.json

   - RecrÃ©e lâ€™architecture LSTM et charge lstm_model.weights.h5

   - preprocess_sequence() : encodage des colonnes catÃ©gorielles + scaling

   - predict() : probabilitÃ© + classe

- main.py

   - Import de lâ€™agent et du LLM Mistral via llama_cpp.Llama

   - Endpoint /predict : retourne directement la sortie de agent.predict()

   - Endpoint /analyze :

      1. Appelle agent.predict()

      2. Calcule des statistiques globales (durÃ©e, dÃ©bit, spkts, dpkts, % HTTP)

      3. Monte un prompt instructif pour Mistral

      4. Renvoie prÃ©diction + stats + explication LLM

- Prompt engineering
Le prompt inclut les statistiques clÃ©s pour fournir un contexte synthÃ©tique, garantissant que Mistral analyse lâ€™ensemble des 10 paquets.

## ğŸ“ˆ RÃ©sultats & Ã‰valuation
- Dataset : UNSWâ€‘NB15 (train + test en .parquet)

- SÃ©quences : fenÃªtres glissantes de 10 paquets, Ã©tiquetÃ©es â€œanomalieâ€ si au moins un paquet malicieux.

- Performance (test) :

   - Accuracy : 88â€¯%

   - F1-score (Normal) : 0.82

   - F1-score (Attack) : 0.90

   - Macro F1 : 0.86


## ğŸ” Visualisations

### Interface
![Interface](capture1.PNG)

### Exemple de prÃ©diction avec explication
![Analyse du LLM](capture2.PNG)

